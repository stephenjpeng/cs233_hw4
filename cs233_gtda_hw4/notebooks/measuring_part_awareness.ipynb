{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import NearestNeighbors  # Students: you can use this implementation to find the \n",
    "                                                # Nearest-Neigbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "c59cdd1537bd75ddd0818327fc390a5__2__\n"
     ]
    }
   ],
   "source": [
    "# Load golden distances (pairwise matrix, or corresponding model/part names in golden_names)\n",
    "golden_part_dist_file = '../data/golden_dists.npz'\n",
    "golden_data = np.load(golden_part_dist_file, allow_pickle=True)\n",
    "golden_part_dist = golden_data['golden_part_dist']\n",
    "golden_names = golden_data['golden_names']\n",
    "print(len(golden_names))  # models-name/part combinations\n",
    "print(golden_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load/organize golden part-aware distances.\n",
    "sn_id_to_parts = defaultdict(list)\n",
    "id_to_part_loc = dict()\n",
    "\n",
    "for i, name in enumerate(golden_names):\n",
    "    # Extract shape-net model ids of golden, map them to their parts.\n",
    "    sn_id, _, part_id, _, _ = name.split('_')\n",
    "    sn_id_to_parts[sn_id].append(part_id)\n",
    "    \n",
    "    # Map shape-net model id and part_id to location in distance matrix, (the order is the same).\n",
    "    id_to_part_loc[(sn_id, part_id)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        pc_ae_out1024_ PART AWARENESS: \n",
      "\n",
      "        Cumulative encoding distance = 401.7189 \n",
      "        Avg. shared parts = 3.15 \n",
      "        Avg. latent distance = 0.21    \n",
      "    \n",
      "\n",
      "        part_pc_ae_out1024_ PART AWARENESS: \n",
      "\n",
      "        Cumulative encoding distance = 410.4051 \n",
      "        Avg. shared parts = 3.19 \n",
      "        Avg. latent distance = 0.30    \n",
      "    \n",
      "\n",
      "        experiment_ PART AWARENESS: \n",
      "\n",
      "        Cumulative encoding distance = 430.8522 \n",
      "        Avg. shared parts = 3.17 \n",
      "        Avg. latent distance = 0.20    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "out_n = 1024\n",
    "\n",
    "for model_tag in [f'pc_ae_out{out_n}_', f'part_pc_ae_out{out_n}_', f'experiment_']:\n",
    "    if model_tag != 'random':\n",
    "        ae_emb_file = f'../data/out/{model_tag}_latent_codes.npz'\n",
    "        in_d = np.load(ae_emb_file)\n",
    "\n",
    "        latent_codes = in_d['latent_codes']\n",
    "        test_names = in_d['test_names']\n",
    "    else:\n",
    "        latent_codes = np.random.rand(len(test_names), 123)\n",
    "\n",
    "    # TODO: Use golden distances and matchings to solve question (g)\n",
    "    nn = NearestNeighbors(n_neighbors=2)\n",
    "    nn.fit(latent_codes)\n",
    "\n",
    "    encoding_distances = np.zeros(len(test_names))\n",
    "    num_shared_parts = np.zeros(len(test_names))\n",
    "    latent_distances = np.empty(len(test_names))\n",
    "    for i, sn_name in enumerate(test_names):\n",
    "        parts_of_model = set(sn_id_to_parts[sn_name])\n",
    "\n",
    "        nn_distances, nn_indices = nn.kneighbors([latent_codes[i]],  return_distance=True)\n",
    "        latent_distances[i] = nn_distances[0, 1]\n",
    "        matched_neighbor = test_names[nn_indices[0, 1]] # Students find the model's name of the Nearest-Neighbor\n",
    "        parts_of_neighbor = set(sn_id_to_parts[matched_neighbor])\n",
    "\n",
    "        # compute the requested distances.\n",
    "        # Use id_to_part_loc for each model/part combination\n",
    "\n",
    "        parts_in_both = parts_of_model.intersection(parts_of_neighbor)\n",
    "        for k in parts_in_both:\n",
    "            encoding_distances[i] += golden_part_dist[id_to_part_loc[(sn_name, k)], id_to_part_loc[(matched_neighbor, k)]]\n",
    "            num_shared_parts[i] += 1\n",
    "\n",
    "        parts_only_model = parts_of_model.difference(parts_of_neighbor)\n",
    "        parts_only_neighbor = parts_of_neighbor.difference(parts_of_model)\n",
    "        \n",
    "        # for k in parts_only_B:\n",
    "        #     encoding_distances[i] += max([golden_part_dist[id_to_part_loc[(matched_neighbor, k)], id_to_part_loc[(sn_name, u)]] for u in parts_of_model])\n",
    "        \n",
    "        cand_distances = [0] * 4\n",
    "        for u in parts_of_model:\n",
    "            for k in parts_only_neighbor:\n",
    "                cand_distances[int(u) - 1] += golden_part_dist[id_to_part_loc[(matched_neighbor, k)], id_to_part_loc[(sn_name, u)]]\n",
    "        encoding_distances[i] += max(cand_distances)\n",
    "\n",
    "    print(f'''\n",
    "        {model_tag} PART AWARENESS: \\n\n",
    "        Cumulative encoding distance = {encoding_distances.sum():.4f} \n",
    "        Avg. shared parts = {num_shared_parts.mean():.2f} \n",
    "        Avg. latent distance = {latent_distances.mean():.2f}    \n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    IDEAL PART AWARENESS: \n",
      "\n",
      "    Cumulative encoding distance = 322.3948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BEST POSSIBLE PART DISTANCES\n",
    "encoding_distances = np.zeros(len(test_names))\n",
    "for i, sn_name in enumerate(test_names):\n",
    "    parts_of_model = set(sn_id_to_parts[sn_name])\n",
    "\n",
    "    min_distance = np.inf\n",
    "    # greedily search for the best possible match\n",
    "    for matched_neighbor in test_names:\n",
    "        if matched_neighbor == sn_name:\n",
    "            continue\n",
    "        distance = 0\n",
    "        parts_of_neighbor = set(sn_id_to_parts[matched_neighbor])\n",
    "\n",
    "        # compute the requested distances.\n",
    "        # Use id_to_part_loc for each model/part combination\n",
    "        parts_in_both = parts_of_model.intersection(parts_of_neighbor)\n",
    "        for k in parts_in_both:\n",
    "            distance += golden_part_dist[id_to_part_loc[(sn_name, k)], id_to_part_loc[(matched_neighbor, k)]]\n",
    "\n",
    "        parts_only_model = parts_of_model.difference(parts_of_neighbor)\n",
    "        parts_only_neighbor = parts_of_neighbor.difference(parts_of_model)\n",
    "        # for k in parts_only_A:\n",
    "        #     distance += max([golden_part_dist[id_to_part_loc[(matched_neighbor, k)], id_to_part_loc[(sn_name, u)]] for u in parts_of_model])\n",
    "\n",
    "        # part distance as in homework\n",
    "        cand_distances = [0] * 4\n",
    "        for u in parts_of_model:\n",
    "            for k in parts_only_neighbor:\n",
    "                cand_distances[int(u) - 1] += golden_part_dist[id_to_part_loc[(matched_neighbor, k)], id_to_part_loc[(sn_name, u)]]\n",
    "        distance += max(cand_distances)\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "    encoding_distances[i] = min_distance\n",
    "\n",
    "print(f'''\n",
    "    IDEAL PART AWARENESS: \\n\n",
    "    Cumulative encoding distance = {encoding_distances.sum():.4f}\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
