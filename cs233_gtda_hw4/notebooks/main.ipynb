{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "## Imports based on our ready-to-use code (after you pip-install the cs233_gtda_hw4 package)\n",
    "from cs233_gtda_hw4.in_out.utils import make_data_loaders\n",
    "from cs233_gtda_hw4.in_out.utils import save_state_dicts, load_state_dicts\n",
    "from cs233_gtda_hw4.in_out import pointcloud_dataset\n",
    "from cs233_gtda_hw4.in_out.plotting import plot_3d_point_cloud\n",
    "\n",
    "\n",
    "## Imports you might use if you follow are scaffold code (it is OK to use your own stucture of the models)\n",
    "from cs233_gtda_hw4.models import PointcloudAutoencoder\n",
    "from cs233_gtda_hw4.models import PartAwarePointcloudAutoencoder\n",
    "from cs233_gtda_hw4.models.point_net import PointNet\n",
    "from cs233_gtda_hw4.models.mlp import MLP\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Fixed Settings (we do not expect you to change these)\n",
    "## \n",
    "\n",
    "n_points = 1024  # number of points of each point-cloud\n",
    "n_parts = 4      # max number of parts of each shape\n",
    "n_train_epochs = 400\n",
    "\n",
    "# Students: feel free to change below -ONLY- for the bonus Question:\n",
    "# I.e., use THESE hyper-parameters when you train for the non-bonus questions.\n",
    "\n",
    "part_lambda = 0.005  # for the part-aware AE you will be using (summing) two losses:\n",
    "                     # chamfer + cross-entropy\n",
    "                     # do it like this: chamfer + (part_lambda * cross-entropy), \n",
    "                     # i.e. we are scaling down the cross-entropy term\n",
    "init_lr = 0.009  # initial learning-rate, tested by us with ADAM optimizer (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Students: feel free to change below:\n",
    "\n",
    "# batch-size of data loaders\n",
    "batch_size = 128 # if you can keep this too as is keep it, \n",
    "                 # but if it is too big for your GPU, feel free to change it.\n",
    "\n",
    "# which device to use: cpu or cuda?\n",
    "device = 'cpu'     # Note: only the \"alternative\" (slower) chamfer_loss in losses/nn_distance can run in cpu.\n",
    "# device = 'cuda'\n",
    "\n",
    "top_in_dir = '../data/'\n",
    "top_out_dir = '../data/out/'\n",
    "if not osp.exists(top_out_dir):\n",
    "    os.makedirs(top_out_dir)\n",
    "    \n",
    "top_log_dir = '../data/logs/'\n",
    "if not osp.exists(top_log_dir):\n",
    "    os.makedirs(top_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-examples train 750\n",
      "N-examples test 150\n",
      "N-examples val 50\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DATA:\n",
    "\n",
    "loaders = make_data_loaders(top_in_dir, batch_size)\n",
    "\n",
    "for split, loader in loaders.items():\n",
    "    print('N-examples', split, len(loader.dataset))\n",
    "    \n",
    "# BUILD MODELS:\n",
    "### TODO: Student on your own:\n",
    "\n",
    "encoder = PointNet()\n",
    "decoder = MLP(128, [256, 384, 3])\n",
    "# part_classifier = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_aware_model = False # or True\n",
    "\n",
    "if part_aware_model:\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "#     model = PartAwarePointcloudAutoencoder().to(device) # Students Work here\n",
    "    model_tag = 'part_pc_ae'\n",
    "else:\n",
    "    model = PointcloudAutoencoder(encoder, decoder).to(device)  # Students Work here\n",
    "    model_tag = 'pc_ae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)  # Students uncomment once you have defined your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3e7c8d08f848d4af5d570ad7a78ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f495b958f540d9838a739e69cf8307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfa846909204f0298286fafd8b8c1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b0eacee4da4ae089337c8a490007f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2baff33f1c0a431eae6b3095ce6588d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee7135d684243d1851970c9e3ebe29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dbd5d972034b699c984cffd95e5cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2d14fcaa324965a7e63a37fe61e6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f9690053c848de8d8e06e39153b1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926e1c4f9e6c49e5b81330ce9b43729e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8978c6e4db5144e79dd70048861b4481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87c57c09a6407ab7e72363a9294397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6134ac5b35634645a6ca6516a8f55fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6304ba7770db427da11059cd66ccdd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d7b72c290b48b5a0dbaf09559d35ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d547119f5fe84f5e96e5cfecb9dc1b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d165b2247d534117b778249330697f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac12bf832dac4779a7a40d025628158e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee03c0f655044c5b2df695935f80208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0afa899eeac49e6a93c250f48e7b7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Train for multiple epochs your model.\n",
    "# Students: the below for-loops are optional, feel free to structure your training \n",
    "# differently.\n",
    "\n",
    "min_val_loss = np.Inf\n",
    "out_file = osp.join(top_out_dir, model_tag + 'best_model.pth')\n",
    "start_epoch = 1\n",
    "\n",
    "writer = SummaryWriter(log_dir=osp.join(top_log_dir, model_tag + time.strftime(\"%Y%m%d-%H%M%S\")))\n",
    "for epoch in tqdm(range(start_epoch, start_epoch + n_train_epochs)):\n",
    "    for phase in ['train', 'val', 'test']:\n",
    "        # Students Work Here.\n",
    "        if phase == 'train':\n",
    "            epoch_losses = model.train_for_one_epoch(loaders[phase], optimizer, device)\n",
    "            writer.add_scalar('Loss/train', epoch_losses, epoch)\n",
    "        else:\n",
    "            recon_loss = model.reconstruct(loaders[phase], device)\n",
    "            writer.add_scalar(f'Loss/{phase}', recon_loss, epoch)\n",
    "\n",
    "        # Save model if validation loss improved.\n",
    "        if phase == 'val' and recon_loss < min_val_loss:\n",
    "            min_val_loss = recon_loss\n",
    "           \n",
    "            # If you save the model like this, you can use the code below to load it. \n",
    "            save_state_dicts(out_file, epoch=epoch, model=model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with best per-validation loss (uncomment when ready)\n",
    "# best_epoch = load_state_dicts(out_file, model=model)\n",
    "# print('per-validation optimal epoch', best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students TODO: MAKE your plots and analysis\n",
    "\n",
    "# 5 examples to visualize per questions (e, f)\n",
    "examples_to_visualize = ['8a67fd47001e52414c350d7ea5fe2a3a',\n",
    "                         '1e0580f443a9e6d2593ebeeedbff73b',\n",
    "                         'd3562f992aa405b214b1fd95dbca05',\n",
    "                         '4e8d8792a3a6390b36b0f2a1430e993a',\n",
    "                         '58479a7b7c157865e68f66efebc71317']\n",
    "\n",
    "# You can (also) use the function for the reconstructions or the part-predictions \n",
    "# (for the latter check the kwargs parameter 'c' of matplotlib.\n",
    "    # plot_3d_point_cloud, eg. try plot_3d_point_cloud(loaders['test'].dataset.pointclouds[0])\n",
    "    \n",
    "model.eval()   # Do not forget this.! We are not training any more (OK, since we do not \n",
    "               # have batch-norm, drop-out etc. this is not so important, however it is good standard \n",
    "               # practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, save the latent codes of the test data and go to the \n",
    "# measuring_part_awareness and tsne_plot_with_latent_codes code.\n",
    "\n",
    "latent_codes = []\n",
    "\n",
    "# Students TODO: Extract the latent codes and save them, so you can analyze them later.\n",
    "\n",
    "\n",
    "np.savez(osp.join(top_out_dir, model_tag +'_latent_codes'), \n",
    "         latent_codes=latent_codes, \n",
    "         test_names=test_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
